"""
Streamlit ê¸°ë°˜ Lecture-RAG ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
ê°•ì˜ë¡ì„ ì¸ë±ì‹±í•˜ê³  ì§ˆì˜ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤
"""
from __future__ import annotations
import re
from pathlib import Path
from typing import Optional

import streamlit as st

from .config import Config
from .vector_store import VectorStore
from .llm_handler import LLMHandler


class LectureRAGApp:
    """Lecture-RAG"""
    
    def __init__(self):
        self.config = Config.from_env()
        self._setup_page()
    
    def _setup_page(self):
        """í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •"""
        st.set_page_config(
            page_title="Lecture-RAG", 
            page_icon="ğŸ“š", 
            layout="wide"
        )
        st.title("Lecture-RAG")
    
    def _render_sidebar(self) -> tuple[VectorStore, str, float]:
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.header("ì„¤ì •")
            
            # ë²¡í„° ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ ì„¤ì •
            store_dir_str = st.text_input(
                "FAISS ì €ì¥ ë””ë ‰í„°ë¦¬", 
                value=self.config.default_store_dir
            )
            store_dir = Path(store_dir_str)
            vector_store = VectorStore(store_dir)
            
            # LLM ëª¨ë¸ ì„¤ì •
            available_models = [
                "gpt-3.5-turbo",
                "gpt-4o-mini",
                "gpt-4o",
                "claude-3-haiku-20240307",
                "claude-3-sonnet-20240229",
                "claude-3-opus-20240229",
                "gemini-1.5-flash",
                "gemini-1.5-pro"
            ]
            
            # í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ì´ ëª©ë¡ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if self.config.model_name not in available_models:
                available_models.insert(0, self.config.model_name)
            
            model = st.selectbox(
                "LLM ëª¨ë¸", 
                options=available_models,
                index=available_models.index(self.config.model_name)
            )
            temp = st.slider(
                "Temperature", 
                0.0, 1.0, 
                self.config.temperature, 
                0.05
            )
            
            st.caption("â€» OpenAI ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            # ì¸ë±ì‹± ì„¹ì…˜
            self._render_indexing_section(vector_store, model, temp)
            
            return vector_store, model, temp
    
    def _render_indexing_section(
        self, 
        vector_store: VectorStore, 
        model: str, 
        temp: float
    ):
        """ì¸ë±ì‹± ì„¹ì…˜ ë Œë”ë§"""
        st.divider()
        st.subheader("ì¸ë±ì‹±")
        
        upload = st.file_uploader(
            "ê°•ì˜ë¡ íŒŒì¼ ì—…ë¡œë“œ(.txt, .md ë“±)", 
            type=["txt", "md", "py", "mdx"], 
            accept_multiple_files=False
        )
        manual_path = st.text_input("ë˜ëŠ” ë¡œì»¬ ê°•ì˜ë¡ ê²½ë¡œ ì…ë ¥", value="ê°•ì˜ë¡.txt")

        if st.button("ì¸ë±ì‹± ì‹¤í–‰", type="primary"):
            self._handle_indexing(vector_store, upload, manual_path, model, temp)
    
    def _handle_indexing(
        self, 
        vector_store: VectorStore, 
        upload: Optional[st.runtime.uploaded_file_manager.UploadedFile], 
        manual_path: str, 
        model: str, 
        temp: float
    ):
        """ì¸ë±ì‹± ì²˜ë¦¬"""
        # íŒŒì¼ ê²½ë¡œ ê²°ì •
        if upload is not None:
            tmp_path = vector_store.store_dir / "uploaded_lecture.txt"
            tmp_path.write_bytes(upload.read())
            path_to_index = tmp_path
        else:
            path_to_index = Path(manual_path)

        if not path_to_index.exists():
            st.error(f"ê°•ì˜ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path_to_index}")
            return
        
        # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
        config = Config(model_name=model, temperature=temp)
        config.to_env()
        
        # ì¸ë±ì‹± ì‹¤í–‰
        with st.spinner("ì¸ë±ì‹± ì¤‘..."):
            n_docs, allowed = vector_store.index_document(path_to_index)
        
        st.success(f"ì¸ë±ì‹± ì™„ë£Œ! ë¬¸ì„œ ì¡°ê° {n_docs}ê°œ ìƒì„±")
        with st.expander("í—ˆìš© í† í°(ëª¨ë“ˆ/ì‹¬ë³¼) ë³´ê¸°"):
            st.json(allowed)
    
    def _render_qa_section(
        self, 
        vector_store: VectorStore, 
        model: str, 
        temp: float
    ):
        """ì§ˆì˜ì‘ë‹µ ì„¹ì…˜ ë Œë”ë§"""
        st.divider()
        
        # ì§ˆë¬¸ ì…ë ¥ ë° ì˜µì…˜ ì„¤ì •
        colQ, colOpt = st.columns([2, 1], vertical_alignment="top")
        
        with colQ:
            st.subheader("ì§ˆì˜ì‘ë‹µ")
            query = st.text_input(
                "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", 
                placeholder="ì˜ˆ) ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜ ë§Œë“¤ì–´ì¤˜"
            )
        
        with colOpt:
            topk = st.slider(
                "Top-K ë¬¸ì„œ", 
                min_value=self.config.min_top_k, 
                max_value=self.config.max_top_k, 
                value=self.config.default_top_k, 
                step=1
            )
        
        ask = st.button("ë‹µë³€ ìƒì„±", type="primary")
        
        if ask:
            self._handle_qa(vector_store, query, topk, model, temp)
    
    def _handle_qa(
        self, 
        vector_store: VectorStore, 
        query: str, 
        topk: int, 
        model: str, 
        temp: float
    ):
        """ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬"""
        if not query.strip():
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
            return
        
        # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
        config = Config(model_name=model, temperature=temp)
        config.to_env()
        
        # ë¬¸ì„œ ê²€ìƒ‰
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            try:
                docs, allowed = vector_store.search(query, k=topk)
            except Exception as e:
                st.error(f"ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¸ë±ì‹±ì„ ìˆ˜í–‰í•˜ì„¸ìš”. ìƒì„¸: {e}")
                return

        if not docs:
            st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì¸ë±ì‹±ì„ ë¨¼ì € ìˆ˜í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        
        # LLM ë‹µë³€ ìƒì„±
        llm_handler = LLMHandler(config)
        with st.spinner("LLM ì‘ë‹µ ìƒì„± ì¤‘..."):
            answer = llm_handler.generate_answer(query, docs, allowed)
        
        # ë¯¸í—ˆìš© í† í° ë¡œê·¸ (ë””ë²„ê¹…ìš©)
        unknown_tokens = llm_handler._check_unknown_tokens(answer, allowed)
        if unknown_tokens:
            with st.expander("ë¯¸í—ˆìš© í† í° ê°ì§€ ë¡œê·¸", expanded=False):
                st.write(", ".join(sorted(set(unknown_tokens))))
        
        # ê²°ê³¼ í‘œì‹œ
        st.subheader("ë‹µë³€")
        st.markdown(answer)
        
        # ê±°ì ˆ ì‘ë‹µì¸ì§€ í™•ì¸í•˜ì—¬ ìŠ¤ë‹ˆí« í‘œì‹œ ì—¬ë¶€ ê²°ì •
        rejection_keywords = [
            "ê°•ì˜ë¡ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ì£¼ì œ",
            "ê°•ì˜ë¡ì— ì—†ëŠ” ë‚´ìš©",
            "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†",
            "ê°•ì˜ë¡ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†"
        ]
        
        is_rejection = any(keyword in answer for keyword in rejection_keywords)
        
        if not is_rejection:
            self._render_evidence_snippets(docs)
        else:
            st.info("ğŸ’¡ ê´€ë ¨ ë‚´ìš©ì´ ê°•ì˜ë¡ì— ì—†ì–´ ê·¼ê±° ìŠ¤ë‹ˆí«ì„ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def _render_evidence_snippets(self, docs):
        """ê·¼ê±° ìŠ¤ë‹ˆí«ë“¤ì„ ë Œë”ë§"""
        st.subheader("ê·¼ê±° ìŠ¤ë‹ˆí«")
        
        for i, d in enumerate(docs, 1):
            meta = d.metadata
            location_info = f"ë¼ì¸ {meta.get('start_line', '?')}-{meta.get('end_line', '?')}"
            first_line = meta.get('first_line_preview', '')
            
            # ë‚ ì§œ ê¸°ë°˜ ì²­í‚¹ì¸ ê²½ìš° ë‚ ì§œ í‘œì‹œ
            if meta.get('kind') == 'lecture_date':
                date = meta.get('date', 'Unknown')
                title = f"ğŸ“… {date} | {location_info} | {first_line}"
            else:
                title = f"Chunk {i} | {meta.get('kind')} | {location_info} | ì‹œì‘: {first_line}"
            
            with st.expander(title, expanded=False):
                # ìœ„ì¹˜ ì •ë³´ í‘œì‹œ
                if meta.get('kind') == 'lecture_date':
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.caption(f"ğŸ“… ê°•ì˜ì¼: {meta.get('date', 'Unknown')}")
                    with col2:
                        st.caption(f"ğŸ“ ìœ„ì¹˜: {location_info}")
                    with col3:
                        st.caption(f"ğŸ“ ì¤„ ìˆ˜: {meta.get('line_count', '?')}ì¤„")
                else:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.caption(f"ğŸ“ ìœ„ì¹˜: {location_info}")
                    with col2:
                        st.caption(f"ğŸ“ ì¤„ ìˆ˜: {meta.get('line_count', '?')}ì¤„")
                    with col3:
                        st.caption(f"ğŸ·ï¸ íƒ€ì…: {meta.get('kind')}")
                
                # ë‚´ìš© í‘œì‹œ
                snippet = d.page_content
                language = "python" if meta.get('kind') == 'code' else "text"
                st.code(snippet, language=language)
                
                # ì›ë³¸ íŒŒì¼ì—ì„œ ì°¾ëŠ” ë°©ë²• ì•ˆë‚´
                st.info(f"ğŸ’¡ ì›ë³¸ì—ì„œ ì°¾ê¸°: '{meta.get('first_line_preview', '')}' ê²€ìƒ‰í•˜ì—¬ {location_info} í™•ì¸")
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        # ì‚¬ì´ë“œë°” ë Œë”ë§
        vector_store, model, temp = self._render_sidebar()
        
        # ì§ˆì˜ì‘ë‹µ ì„¹ì…˜ ë Œë”ë§
        self._render_qa_section(vector_store, model, temp)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    app = LectureRAGApp()
    app.run()


if __name__ == "__main__":
    main()